<!doctype html>
<html lang="en">
<head>
<meta charset="utf-8">
<!-- CUSTOMIZE THIS! -->
<title>Topic Modeling</title>
<meta name="author" content="Christof Schöch">
<!-- END -->
<meta name="description" content="Slides">
<meta name="apple-mobile-web-app-capable" content="yes">
<meta name="apple-mobile-web-app-status-bar-style" content="black-translucent">
<meta name="viewport" content="width=device-width, initial-scale=1.0, maximum-scale=1.0, user-scalable=no, minimal-ui">
<link rel="stylesheet" href="css/reveal.css">
<link rel="stylesheet" href="css/theme/simple.css" id="theme">
<!-- Code syntax highlighting -->
<link rel="stylesheet" href="lib/css/zenburn.css">
<!-- Printing and PDF exports -->
<script>
var link = document.createElement( 'link' );
link.rel = 'stylesheet';
link.type = 'text/css';
link.href = window.location.search.match( /print-pdf/gi ) ? 'css/print/pdf.css' : 'css/print/paper.css';
document.getElementsByTagName( 'head' )[0].appendChild( link );
</script>
<!--[if lt IE 9]>
<script src="lib/js/html5shiv.js"></script>
<![endif]-->
</head>

<body>
<div class="reveal">
<!-- THIS IS WHERE THE CONTENT GOES! -->
<!-- Any section element inside of this container is displayed as a slide -->
<div class="slides">

<section data-markdown>
<script type="text/template">
# Topic Modeling:<br/>Theorie und Anwendung
<hr/>
<br/>
<p>Vorlesung im Rahmen der <em>Einführung in die <br/>Digital Humanities</em>, Universität Hamburg</p>
<br/>
<hr/>
<p>Christof Schöch<br/>(CLiGS, Universität Würzburg)</p>
<p><img height="50" data-src="img/basics/UWUE.jpg"></img>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;<img height="100" data-src="img/basics/CLiGS.jpg"></img>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;<img height="50" data-src="img/basics/BMBF.jpg"></img></p>
</script>
</section>

<section data-markdown>
<script type="text/template">
## Überblick
1. Einstieg: Wozu Topic Modeling?
2. Theorie: Was ist Topic Modeling?
3. Anwendung: Der Topic Modeling Workflow (tmw)
4. Beispielanalyse: Kriminalroman
5. Fazit
</script>
</section>

<section>

<section data-markdown>
<script type="text/template">
# 1. Einstieg:<br/>Wozu Topic Modeling?
</script>
</section>

<section data-markdown>
<script type="text/template">
## Erste Annäherung
* Topic Modeling ist eine quantitative Methode der Textanalyse <!-- .element: class="fragment" data-fragment-index="1" -->
* Topic Modeling identifiziert automatisch wiederkehrende Themen, Motive, Diskurse <!-- .element: class="fragment" data-fragment-index="2" -->
* Topic Modeling eignet sich insbesondere für sehr große Textsammlungen <!-- .element: class="fragment" data-fragment-index="3" -->
</script>
</section>

<section data-markdown>
<script type="text/template">
## Anwendungsszenarien
* Information Retrieval: Suche nicht nach Einzelbegriffen, sondern nach Themen / Wortfeldern <!-- .element: class="fragment" data-fragment-index="1" -->
* Recommender Systems: Vorschlag thematisch ähnlicher wissenschaftlicher Artikel <!-- .element: class="fragment" data-fragment-index="2" -->
* Exploration von Textsammlungen <!-- .element: class="fragment" data-fragment-index="3" -->
* Literatur- und kulturhistorische Fragestellungen <!-- .element: class="fragment" data-fragment-index="4" -->
</script>
</section>

<section data-markdown>
<script type="text/template">
## Explorative Visualisierung (1)
<p><a href="http://signsat40.signsjournal.org/topic-model/#/model/grid"><img height="500" data-src="img/signs-at-forty.png"></img></a></p>
<p>Signs at 40</p>
</script>
</section>

<section data-markdown>
<script type="text/template">
## Explorative Visualisierung (2)
<p><a href="http://dh.library.yale.edu/projects/vogue/topics/50/"><img height="500" data-src="img/topic-model-of-vogue.png"></img></a></p>
<p>Topic Modeling Vogue</p>
</script>
</section>


<section data-markdown>
<script type="text/template">
## Forschungsbeiträge
* Cameron Blevins: "Topic Modeling Martha Ballard's Diary" (2010): Tagebuch <!-- .element: class="fragment" data-fragment-index="1" -->
* Ted Underwood und Andrew Goldstone (2012): "What can topic models of PMLA teach us...": Fachgeschichte <!-- .element: class="fragment" data-fragment-index="2" -->
* Lisa Rhody, "Topic Modeling and Figurative Language" (2012): Poesie <!-- .element: class="fragment" data-fragment-index="3" -->
* Matthew Jockers, Macroanalysis (2013): Roman, Nationalität und Gender <!-- .element: class="fragment" data-fragment-index="4" -->
* Ben Schmidt: "Typical TV episodes" (2014): Fernseh-Serien, Zeitverlauf <!-- .element: class="fragment" data-fragment-index="5" -->
* Christof Schöch, "Topic Modeling Genre" (2017): Drama, Untergattungen <!-- .element: class="fragment" data-fragment-index="6" -->
</script>
</section>

</section>
<section>



<section data-markdown>
<script type="text/template">
# 2. Theorie:</br>Was ist Topic Modeling?
</script>
</section>

<section data-markdown>
<script type="text/template">
## Wörter, Topics, Dokumente
<p><img height="500" data-src="img/tm_blei.png"></img></p>
<p>(David Blei, "Probabilistic Topic Models", 2012)</p>
</script>
</section>

<section data-markdown>
<script type="text/template">
## Topic Modeling: Grundidee
* Entdeckt Wörter, die immer wieder gemeinsam bzw. in ähnlichen Kontexten vorkommen (=Topics) <!-- .element: class="fragment" data-fragment-index="1" -->
* Distributionelle Semantik: "a word is characterized by the company it keeps" (John Firth, 1957) <!-- .element: class="fragment" data-fragment-index="2" -->
* Rein datenbasiert; keinerlei explizites semantisches Wissen fließt ein <!-- .element: class="fragment" data-fragment-index="3" -->
* Berechnet, wie wichtig jeder Topic in jedem Dokument ist <!-- .element: class="fragment" data-fragment-index="4" -->
* Berechnet, wie wichtig jedes Wort in jedem Topic ist <!-- .element: class="fragment" data-fragment-index="5" -->
</script>
</section>

<section data-markdown>
<script type="text/template">
## Topic Modeling: Transformation
* Input <!-- .element: class="fragment" data-fragment-index="1" -->
    * Eine umfangreiche Textsammlung
    * Jedes Dokument als geordnete Liste von Wörtern
* Output <!-- .element: class="fragment" data-fragment-index="2" -->
    * Wahrscheinlichkeiten der Topics in den Dokumenten (Dokumente x Topics)
    * Wahrscheinlichkeit der Wörter in den Topics (Topics x Wörter)
</script>
</section>


<section data-markdown>
<script type="text/template">
## Dokumente x Topics
<p><img height="400" data-src="img/docs-and-topics-in-rank.png"></img></p>
<p>(Jedes Dokument ist eine Wahrscheinlichkeitsverteilung von Topics)
</script>
</section>

<section data-markdown>
<script type="text/template">
## Topics x Wörter
<p><img height="400" data-src="img/word-scores-in-topics.png"></img></p>
<p>(Jeder Topic ist eine Wahrscheinlichkeitsverteilung von Wörtern)
</script>
</section>


<section data-markdown>
<script type="text/template">
## Topic Modeling und Bayes'sche Statistik
>"The computational problem of inferring the hidden topic structure from the documents is the problem of computing the posterior distribution, the conditional distribution of the hidden variables given the documents."

<br/>
<p>(David Blei, "Probabilistic Topic Models", 2012)</p>
<p>LDA: Latent Dirichlet Allocation</p>
</script>
</section>


<section data-markdown>
<script type="text/template">
## LDA: generativ, inferentiell
<p><img height="500" data-src="img/tm_steyvers1.png"></img></p>
<p>(Steyvers and Griffiths, "Probabilistic Topic Modeling", 2006)</p>
</script>
</section>

<section data-markdown>
<script type="text/template">
## LDA: generativ, inferentiell
<p><img height="500" data-src="img/tm_steyvers2.png"></img></p>
<p>(Steyvers and Griffiths, "Probabilistic Topic Modeling", 2006)</p>
</script>
</section>

<!---
<section data-markdown>
<script type="text/template">
## Latent Dirichlet Allocation: plate notation
<p><img height="500" data-src="img/wikipedia_topic-modeling-plate-notation.png"></img></p>
<p>(<https://en.wikipedia.org/wiki/Latent_Dirichlet_allocation>)</p>
</script>
</section>
-->


<section data-markdown>
<script type="text/template">
## How it works exactly, clearly explained
<p><img height="600" data-src="img/sharris_more-explicit-in-step-two.jpg"></img></p>  <!-- .element: class="fragment" data-fragment-index="1" -->
</script>
</section>



</section>
<section>

<section data-markdown>
<script type="text/template">
# 3. Anwendung:<br/>Topic Modeling Workflow</h2>
</script>
</section>

<section data-markdown>
<script type="text/template">
## (2) Topic Modeling Workflow
<p><a href="img/2_topic-modeling-workflow.png"><img height="500" data-src="img/2_topic-modeling-workflow.png"></img></a></p>
<p>(Mallet und Python; siehe <a href="http://github.com/cligs/tmw">github.com/cligs/tmw</a>.)</p>
</script>
</section>


<section data-markdown>
<script type="text/template">
## Umsetzung: Mallet und Python
* MALLET (Machine Learning for Language Toolkit, https://github.com/mimno/Mallet): das eigentliche Topic Modeling 
* Python (Programmiersprache, https://www.python.org/): alles andere drumherum (tmw)
</script>
</section>

<section data-markdown>
<script type="text/template">
## Parameter
* Präprozessieren: Länge der Textsegmente, Lemmatisierung, Feature-Selektion  <!-- .element: class="fragment" data-fragment-index="1" -->
* Modellieren: Anzahl der Topics, Anzahl der Iterationen, Optimierungsmodus  <!-- .element: class="fragment" data-fragment-index="2" -->
* Visualisierung: Berechnung der Mittelwerte, Normalisierungen  <!-- .element: class="fragment" data-fragment-index="3" -->
</script>
</section>



</section>
<section>
    
<section data-markdown>
<script type="text/template">
# 4. Beispielanalyse:</br>Kriminalroman
</script>
</section>

<section data-markdown>
<script type="text/template">
## Textsammlung: 840 frz. Romane
<img height="500" data-src="img/textsammlung.png"></img>
</script>
</section>


<section data-markdown>
<script type="text/template">
## Das verwendete Modell
* Parameter <!-- .element: class="fragment" data-fragment-index="1" -->
    * Textsegmente von 1000 Wörtern
    * Lemmatisierung und Auswahl von N,V,Adj,Adv
    * 80 Topics (getestet: 60-280)
    * keine regelmäßige Hyperparameter-Optimierung
* Evaluation <!-- .element: class="fragment" data-fragment-index="2" -->
    * relevanter Klassifikationstask (Krimi vs. Nicht-Krimi)
    * beste Performance 0.79 mean accuracy
</script>
</section>



<section data-markdown>
<script type="text/template">
## Kriminalroman (prototypisch)
* Längere, narrative, fiktionale Prosa <!-- .element: class="fragment" data-fragment-index="1" -->
* Figureninventar: Ermittler, Verbrecher, Verdächtige, Opfer, Zeugen <!-- .element: class="fragment" data-fragment-index="2" -->
* Handlung: gewalttätiges Verbrechen, rationale Aufklärung <!-- .element: class="fragment" data-fragment-index="3" -->
* Schauplatz: urbaner Raum  <!-- .element: class="fragment" data-fragment-index="4" -->
* => Hypothesen zu erwartbaren Themen <!-- .element: class="fragment" data-fragment-index="5" -->
</script>
</section>



<section data-markdown>
<script type="text/template">
##Topic 10 
<p><a href="img/2_topic10-wordle-comparison.png"><img height="400" data-src="img/2_topic10-wordle-comparison.png"></img></a></p>
<p>Topic 10: Inspektor, Kommissar, Polizei</p>
<p>inhaltlich und statistisch Krimi-spezifisch (p &lt; α=0.01)</p> <!-- .element: class="fragment" data-fragment-index="1" -->
</script>
</section>


<section data-markdown>
<script type="text/template">
##Topic 49
<p><a href="img/2_topic49-wordle-comparison.png"><img height="400" data-src="img/2_topic49-wordle-comparison.png"></img></a></p>
<p>Topic 49: Tod, Verbrechen, töten</p>
<p>inhaltlich und statistisch Krimi-spezifisch (p &lt; α=0.01)</p>
</script>
</section>


<section data-markdown>
<script type="text/template">
##Topic 47
<p><a href="img/2_topic47-wordle-comparison.png"><img height="400" data-src="img/2_topic47-wordle-comparison.png"></img></a></p>
<p>Topic 47: Tür, Zimmer, öffnen; inhaltlich Krimi-spezifisch?</p>
<p>Statistisch Krimi-spezifisch (p &lt; α=0.01)</p> 
</script>
</section>


<section data-markdown>
<script type="text/template">
##Topic 26 
<p><a href="img/2_topic26-wordle-comparison.png"><img height="400" data-src="img/2_topic26-wordle-comparison.png"></img></a></p>
<p>Topic 26: Strand, Sand, Sonne</p>
<p>Statistisch Nicht-Krimi spezifisch (p &lt; α=0.001)</p>
</script>
</section>


<section data-markdown>
<script type="text/template">
## Topics im Textverlauf
<p><a href="img/2_topic002_progression.png"><img height="400" data-src="img/2_topic002_progression.png"></img></a></p>
<p>Topic 2: Richter, Gefängnis, Anwalt</p>
<p>Signifikanz (Krimis): u.a. (1,4), (4,5) signifikant (p &lt; α=0.01)</p>
</script>
</section>


<section data-markdown>
<script type="text/template">
## Topics im Textverlauf
<p><a href="img/2_topic033_progression.png"><img height="400" data-src="img/2_topic033_progression.png"></img></a></p>
<p>Topic 33: schwarz, Haare, tragen, weiß, Auge, Gesicht</p>
<p>Signifikanz (Krimis): alle außer (2,3) signifikant (p &lt; α=0.01)
<br/>(Nicht-Krimis): u.a. (1,3), (2,5),  signifikant (p &lt; α=0.01)</p>
</script>
</section>



<section data-markdown>
<script type="text/template">
## Ergebnisse
* Ein großer Teil der Topics ist distinktiv entweder für Krimis (31/80) oder Nicht-Krimis (21/80) <!-- .element: class="fragment" data-fragment-index="1" -->
* Topics entsprechen nicht nur Themen, sondern auch Handlungsmotiven, Figurengruppen oder Setting <!-- .element: class="fragment" data-fragment-index="2" -->
* Textverlauf: Nur in wenigen Fällen deutliche Trends sichtbar <!-- .element: class="fragment" data-fragment-index="3" -->
* Insgesamt: Wir können Trends in 840 Romanen entdecken, ohne alle Romane zu lesen! <!-- .element: class="fragment" data-fragment-index="4" -->
</script>
</section>

</section>
<section>

<section data-markdown>
<script type="text/template">
# 5. Fazit
</script>
</section>

<section data-markdown>
<script type="text/template">
## Bilanz
* Topic Modeling ist ein sehr mächtiges, quantitatives, sprachunabhängiges Verfahren <!-- .element: class="fragment" data-fragment-index="1" -->
* Topic Models skalieren nicht nur gut, sondern brauchen große Textmengen <!-- .element: class="fragment" data-fragment-index="2" -->
* Topics sind nicht nur Themen, sondern beziehen sich auch auf Motive, Setting, Figuren, Register, Diskurse... <!-- .element: class="fragment" data-fragment-index="3" -->
* Literarische Texte haben andere Topics als Sachtexte; haben Gattungen auch spezifische Topics? <!-- .element: class="fragment" data-fragment-index="4" -->
</script>
</section>


<section data-markdown>
<script type="text/template">
## Lektürehinweise: Theorie und Technik
<small>
* Blei, D. M. (2012). "Probabilistic topic models". In: _Communications of the ACM_, 55(4): 77–84. http://www.cs.princeton.edu/~blei/papers/Blei2012.pdf
* Steyvers, M. and Griffiths, T. (2006). "Probabilistic Topic Models". In: Landauer, T. et al. (eds), _Latent Semantic Analysis: A Road to Meaning_. Laurence Erlbaum.
* Weingart, S. (2012). "Topic Modeling for Humanists: A Guided Tour". In: _The Scottbot Irregular_. http://www.scottbot.net/HIAL/?p=19113

</small>
</script>
</section>

<section data-markdown>
<script type="text/template">
## Lektürehinweise: Anwendungsbeispiele
<small>
* Cameron Blevins. (2010). "Topic Modeling Martha Ballard’s Diary". In: _Historying_. http://historying.org/2010/04/01/topic-modeling-martha-ballards-diary/
* Ted Underwood und Andrew Goldstone (2012)." "What can topic models of PMLA teach us about the history of literary scholarship?" In: _The Stone and the Shell_. http://tedunderwood.com/2012/12/14/what-can-topic-models-of-pmla-teach-us-about-the-history-of-literary-scholarship/
* Lisa Rhody (2012). "Topic Modeling and Figurative Language". In: _Journal of Digital Humanities_, 2(1) http://journalofdigitalhumanities.org/2-1/topic-modeling-and-figurative-language-by-lisa-m-rhody/
* Matthew Jockers (2013). _Macroanalysis - Digital Methods and Literary History_. Champaign, IL: University of Illinois Press.
* Ben Schmidt (2014): "Typical TV episodes: visualizing topics in screen time". Sapping Attention. http://sappingattention.blogspot.de/2014/12/typical-tv-episodes-visualizing-topics.html
* Christof Schöch (2017). "Topic Modeling Genre: An Exploration of French Classical and Enlightenment Drama". In: _Digital Humanities Quarterly_.

</small>
</script>
</section>



</section>

<section data-markdown>
<script type="text/template">
###Vielen Dank!
<br/>
<br/>
<br/>
<hr/>
<p>Folien: <a href="https://christofs.github.io/topic-modeling-vorlesung/#/">christofs.github.io</a>
<br/>
<p>Autor: <a href="http://www.christof-schoech.de">Christof Schöch</a>, Lizenz: <a href="https://creativecommons.org/licenses/by/4.0/">CC-BY</a>, 2016.</p>
</script>
</section>



<!-- DON'T TOUCH UNLESS YOU KNOW WHAT YOU'RE DOING :-) -->
</div>
<script src="lib/js/head.min.js"></script>
<script src="js/reveal.js"></script>
<script>
// Full list of configuration options available at:
// https://github.com/hakimel/reveal.js#configuration
Reveal.initialize({
    controls: true,
    progress: true,
    history: true,
    center: true,
    transition: 'slide', // none/fade/slide/convex/concave/zoom
    // Optional reveal.js plugins
    dependencies: [
        { src: 'lib/js/classList.js', condition: function() { return !document.body.classList; } },
        { src: 'plugin/markdown/marked.js', condition: function() { return !!document.querySelector( '[data-markdown]' ); } },
        { src: 'plugin/markdown/markdown.js', condition: function() { return !!document.querySelector( '[data-markdown]' ); } },
        { src: 'plugin/highlight/highlight.js', async: true, callback: function() { hljs.initHighlightingOnLoad(); } },
        { src: 'plugin/zoom-js/zoom.js', async: true },
        { src: 'plugin/notes/notes.js', async: true }
        ]
    });
</script>
</body>
</html>
